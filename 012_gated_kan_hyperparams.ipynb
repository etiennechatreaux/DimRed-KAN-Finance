{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gated KAN Autoencoder - Hyperparameter Grid Search\n",
        "Test syst√©matique des hyperparam√®tres `lambda_gate_reg` et `lambda_orthogonal` sur les yield curves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Device: cuda\n",
            "   GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n",
            "   Memory: 8.0 GB\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('src')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "import itertools\n",
        "from tqdm.auto import tqdm\n",
        "import gc\n",
        "\n",
        "from src.models.gated_kan_ae import GatedKANAutoencoder\n",
        "from src.utils.yield_curve_data import load_preprocessed_yield_curve\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "torch.set_float32_matmul_precision('medium')\n",
        "\n",
        "# Configuration device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üöÄ Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration de la grille d'hyperparam√®tres\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Hyperparam√®tres √† tester:\n",
            "   lambda_gate_reg: [0.0, 1e-05, 0.0001, 0.001, 0.01]\n",
            "   lambda_orthogonal: [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
            "   Total combinations: 25\n",
            "   Datasets: ['yield_cross_section', 'yield_column_wise']\n",
            "   Total experiments: 50\n"
          ]
        }
      ],
      "source": [
        "# Grille d'hyperparam√®tres pour test nocturne\n",
        "HYPERPARAMS_GRID = {\n",
        "    # Hyperparam√®tres √† tester (pour le constructeur)\n",
        "    'lambda_gate_reg': [0.0, 1e-5, 1e-4, 1e-3, 1e-2],  # 5 valeurs\n",
        "    'lambda_orthogonal': [0.0, 1e-4, 1e-3, 1e-2, 1e-1],  # 5 valeurs\n",
        "    \n",
        "    # Hyperparam√®tres fixes du constructeur (bas√©s sur les meilleures pratiques)\n",
        "    'input_dim': None,  # Sera d√©fini selon le dataset\n",
        "    'k': 3, \n",
        "    'hidden_dims': [5, 4], \n",
        "    'basis_type': 'spline',\n",
        "    'M': 16,\n",
        "    'poly_degree': 5,\n",
        "    'xmin': -3.5,\n",
        "    'xmax': 3.5,\n",
        "    'dropout_p': 0,\n",
        "    'use_silu': True,\n",
        "    'gate_init': 0.5,\n",
        "    'skip_rank': None,  # Sera d√©fini selon input_dim\n",
        "    'loss_type': 'huber',\n",
        "    'huber_delta': 1.0,\n",
        "    'lambda_alpha': 1e-4,\n",
        "    'lambda_group': 1e-5,\n",
        "    'lambda_tv': 1e-4,\n",
        "    'lambda_poly_decay': 0.0\n",
        "}\n",
        "\n",
        "# Param√®tres d'entra√Ænement (pour la m√©thode fit)\n",
        "TRAINING_PARAMS = {\n",
        "    'epochs': 200,  # R√©duit pour test rapide\n",
        "    'batch_size': 128,\n",
        "    'learning_rate': 0.001,\n",
        "    'weight_decay': 1e-5,\n",
        "    'patience': 20,\n",
        "    'lambda_reg': 1.0,\n",
        "    'verbose': False  # Pas de verbose pour la grille\n",
        "}\n",
        "\n",
        "# Datasets √† tester\n",
        "DATASETS = {\n",
        "    'yield_cross_section': {\n",
        "        'normalization': 'cross_section',\n",
        "        'description': 'Yield Curve (Cross-section Z-score)'\n",
        "    },\n",
        "    'yield_column_wise': {\n",
        "        'normalization': 'column_wise', \n",
        "        'description': 'Yield Curve (Column-wise Z-score)'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"üîß Hyperparam√®tres √† tester:\")\n",
        "print(f\"   lambda_gate_reg: {HYPERPARAMS_GRID['lambda_gate_reg']}\")\n",
        "print(f\"   lambda_orthogonal: {HYPERPARAMS_GRID['lambda_orthogonal']}\")\n",
        "print(f\"   Total combinations: {len(HYPERPARAMS_GRID['lambda_gate_reg']) * len(HYPERPARAMS_GRID['lambda_orthogonal'])}\")\n",
        "print(f\"   Datasets: {list(DATASETS.keys())}\")\n",
        "print(f\"   Total experiments: {len(HYPERPARAMS_GRID['lambda_gate_reg']) * len(HYPERPARAMS_GRID['lambda_orthogonal']) * len(DATASETS)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Fonctions utilitaires\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_results_directory():\n",
        "    \"\"\"Cr√©e le r√©pertoire de r√©sultats avec timestamp\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    results_dir = Path(f\"results/gated_kan_hyperparams_{timestamp}\")\n",
        "    results_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Sauvegarder la configuration\n",
        "    config = {\n",
        "        'hyperparams_grid': HYPERPARAMS_GRID,\n",
        "        'datasets': DATASETS,\n",
        "        'timestamp': timestamp,\n",
        "        'device': str(device)\n",
        "    }\n",
        "    \n",
        "    with open(results_dir / 'config.json', 'w') as f:\n",
        "        json.dump(config, f, indent=2, default=str)\n",
        "    \n",
        "    return results_dir\n",
        "\n",
        "def load_dataset(normalization_type):\n",
        "    \"\"\"Charge un dataset de yield curve\"\"\"\n",
        "    df = load_preprocessed_yield_curve(\n",
        "        start=\"2000-01-01\",\n",
        "        normalization=normalization_type\n",
        "    )\n",
        "    \n",
        "    # Conversion en tenseurs\n",
        "    X = torch.tensor(df.values, dtype=torch.float32)\n",
        "    dates = df.index\n",
        "    \n",
        "    return X, dates, df.columns\n",
        "\n",
        "def train_gated_kan_config(X, model_config, training_config, dataset_name, cv_splits=3):\n",
        "    \"\"\"Entra√Æne un Gated KAN AE avec une configuration donn√©e\"\"\"\n",
        "    results = {\n",
        "        'dataset': dataset_name,\n",
        "        'model_config': model_config.copy(),\n",
        "        'training_config': training_config.copy(),\n",
        "        'cv_scores': [],\n",
        "        'mean_score': 0,\n",
        "        'std_score': 0,\n",
        "        'training_times': [],\n",
        "        'final_gate_values': [],\n",
        "        'orthogonality_violations': [],\n",
        "        'success': False\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        # Configuration du mod√®le (pour le constructeur)\n",
        "        model_params = model_config.copy()\n",
        "        model_params['input_dim'] = X.shape[1]\n",
        "        model_params['skip_rank'] = min(X.shape[1] // 4, 32)  # Heuristique\n",
        "        \n",
        "        # Cross-validation temporelle\n",
        "        tscv = TimeSeriesSplit(n_splits=cv_splits)\n",
        "        \n",
        "        for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
        "            X_train, X_val = X[train_idx], X[val_idx]\n",
        "            \n",
        "            # Cr√©ation du mod√®le\n",
        "            model = GatedKANAutoencoder(**model_params)\n",
        "            model.to(device)\n",
        "            \n",
        "            # Entra√Ænement\n",
        "            start_time = datetime.now()\n",
        "            history = model.fit(\n",
        "                X_train=X_train,\n",
        "                X_val=X_val,\n",
        "                **training_config  # Utilise les param√®tres d'entra√Ænement\n",
        "            )\n",
        "            training_time = (datetime.now() - start_time).total_seconds()\n",
        "            \n",
        "            # √âvaluation\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                X_val_hat, _, gate, _, _ = model(X_val.to(device))\n",
        "                val_loss = nn.functional.mse_loss(X_val_hat, X_val.to(device)).item()\n",
        "                \n",
        "                # M√©triques sp√©cifiques au Gated KAN\n",
        "                gate_info = model.get_gate_info()\n",
        "                final_gate = gate_info['kan_contribution']\n",
        "                orth_violation = history['orthogonality_violation'][-1] if 'orthogonality_violation' in history else 0.0\n",
        "            \n",
        "            results['cv_scores'].append(val_loss)\n",
        "            results['training_times'].append(training_time)\n",
        "            results['final_gate_values'].append(final_gate)\n",
        "            results['orthogonality_violations'].append(orth_violation)\n",
        "            \n",
        "            # Nettoyage m√©moire\n",
        "            del model, history\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "        \n",
        "        # Statistiques finales\n",
        "        results['mean_score'] = np.mean(results['cv_scores'])\n",
        "        results['std_score'] = np.std(results['cv_scores'])\n",
        "        results['success'] = True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur pour {dataset_name}: {str(e)}\")\n",
        "        results['error'] = str(e)\n",
        "    \n",
        "    return results\n",
        "\n",
        "def save_results(results, results_dir):\n",
        "    \"\"\"Sauvegarde les r√©sultats\"\"\"\n",
        "    results_file = results_dir / f\"results_{datetime.now().strftime('%H%M%S')}.json\"\n",
        "    \n",
        "    # Conversion pour JSON\n",
        "    json_results = []\n",
        "    for result in results:\n",
        "        json_result = result.copy()\n",
        "        # Conversion des listes numpy\n",
        "        for key in ['cv_scores', 'training_times', 'final_gate_values', 'orthogonality_violations']:\n",
        "            if key in json_result:\n",
        "                json_result[key] = [float(x) for x in json_result[key]]\n",
        "        json_results.append(json_result)\n",
        "    \n",
        "    with open(results_file, 'w') as f:\n",
        "        json.dump(json_results, f, indent=2, default=str)\n",
        "    \n",
        "    return results_file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Chargement des datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Loading yield_cross_section...\n",
            "Loading existing file: data\\raw\\fred_yield_curve.csv\n",
            "FRED Yield Curve: 9303 rows √ó 8 cols\n",
            "Column 1M has 3020 NaNs\n",
            "Dropping columns: ['1M']\n",
            "Cross-section z-score shape: (9303, 7)\n",
            "Column-wise z-score shape: (9303, 7)\n",
            "   ‚úÖ 9303 samples, 7 features\n",
            "üìÇ Loading yield_column_wise...\n",
            "Loading existing file: data\\raw\\fred_yield_curve.csv\n",
            "FRED Yield Curve: 9303 rows √ó 8 cols\n",
            "Column 1M has 3020 NaNs\n",
            "Dropping columns: ['1M']\n",
            "Cross-section z-score shape: (9303, 7)\n",
            "Column-wise z-score shape: (9303, 7)\n",
            "   ‚úÖ 9303 samples, 7 features\n",
            "\n",
            "üéØ Total datasets loaded: 2\n"
          ]
        }
      ],
      "source": [
        "# Chargement des datasets\n",
        "datasets = {}\n",
        "for name, config in DATASETS.items():\n",
        "    print(f\"üìÇ Loading {name}...\")\n",
        "    X, dates, features = load_dataset(config['normalization'])\n",
        "    datasets[name] = {\n",
        "        'X': X,\n",
        "        'dates': dates,\n",
        "        'features': features,\n",
        "        'description': config['description']\n",
        "    }\n",
        "    print(f\"   ‚úÖ {X.shape[0]} samples, {X.shape[1]} features\")\n",
        "\n",
        "print(f\"\\nüéØ Total datasets loaded: {len(datasets)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Grille de recherche principale\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Results directory: results\\gated_kan_hyperparams_20250903_052323\n",
            "üîç Total configurations to test: 25\n",
            "‚è±Ô∏è  Estimated time: 100 minutes (2min per config)\n",
            "üåô Perfect for overnight training!\n"
          ]
        }
      ],
      "source": [
        "# Cr√©ation du r√©pertoire de r√©sultats\n",
        "results_dir = create_results_directory()\n",
        "print(f\"üìÅ Results directory: {results_dir}\")\n",
        "\n",
        "# G√©n√©ration de toutes les combinaisons\n",
        "all_configs = list(itertools.product(\n",
        "    HYPERPARAMS_GRID['lambda_gate_reg'],\n",
        "    HYPERPARAMS_GRID['lambda_orthogonal']\n",
        "))\n",
        "\n",
        "print(f\"üîç Total configurations to test: {len(all_configs)}\")\n",
        "print(f\"‚è±Ô∏è  Estimated time: {len(all_configs) * len(datasets) * 2} minutes (2min per config)\")\n",
        "print(f\"üåô Perfect for overnight training!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting hyperparameter grid search at 05:23:25\n",
            "üìä Testing 25 configurations on 2 datasets\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d31aa5f5e8464220ace1a1e93c036d88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Configurations:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîß Config 1/25: Œª_gate=0e+00, Œª_orth=0e+00\n",
            "   üìä Testing on yield_cross_section...\n"
          ]
        }
      ],
      "source": [
        "# Boucle principale d'entra√Ænement\n",
        "all_results = []\n",
        "start_time = datetime.now()\n",
        "\n",
        "print(f\"üöÄ Starting hyperparameter grid search at {start_time.strftime('%H:%M:%S')}\")\n",
        "print(f\"üìä Testing {len(all_configs)} configurations on {len(datasets)} datasets\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for config_idx, (lambda_gate_reg, lambda_orthogonal) in enumerate(tqdm(all_configs, desc=\"Configurations\")):\n",
        "    print(f\"\\nüîß Config {config_idx+1}/{len(all_configs)}: Œª_gate={lambda_gate_reg:.0e}, Œª_orth={lambda_orthogonal:.0e}\")\n",
        "    \n",
        "    # Configuration du mod√®le pour cette it√©ration\n",
        "    model_config = HYPERPARAMS_GRID.copy()\n",
        "    model_config['lambda_gate_reg'] = lambda_gate_reg\n",
        "    model_config['lambda_orthogonal'] = lambda_orthogonal\n",
        "    \n",
        "    # Test sur chaque dataset\n",
        "    for dataset_name, dataset_info in datasets.items():\n",
        "        print(f\"   üìä Testing on {dataset_name}...\")\n",
        "        \n",
        "        result = train_gated_kan_config(\n",
        "            X=dataset_info['X'],\n",
        "            model_config=model_config,\n",
        "            training_config=TRAINING_PARAMS,\n",
        "            dataset_name=dataset_name\n",
        "        )\n",
        "        \n",
        "        all_results.append(result)\n",
        "        \n",
        "        if result['success']:\n",
        "            print(f\"      ‚úÖ Score: {result['mean_score']:.6f} ¬± {result['std_score']:.6f}\")\n",
        "            print(f\"      üéõÔ∏è  Gate: {np.mean(result['final_gate_values']):.3f}\")\n",
        "            print(f\"      üîÄ Orth_viol: {np.mean(result['orthogonality_violations']):.4f}\")\n",
        "        else:\n",
        "            print(f\"      ‚ùå Failed: {result.get('error', 'Unknown error')}\")\n",
        "    \n",
        "    # Sauvegarde interm√©diaire tous les 5 configs\n",
        "    if (config_idx + 1) % 5 == 0:\n",
        "        save_results(all_results, results_dir)\n",
        "        print(f\"   üíæ Intermediate save at config {config_idx+1}\")\n",
        "    \n",
        "    # Nettoyage m√©moire\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "end_time = datetime.now()\n",
        "total_time = (end_time - start_time).total_seconds() / 3600  # en heures\n",
        "\n",
        "print(f\"\\nüéâ Grid search completed!\")\n",
        "print(f\"‚è±Ô∏è  Total time: {total_time:.2f} hours\")\n",
        "print(f\"üìä Total experiments: {len(all_results)}\")\n",
        "print(f\"‚úÖ Successful: {sum(1 for r in all_results if r['success'])}\")\n",
        "print(f\"‚ùå Failed: {sum(1 for r in all_results if not r['success'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Sauvegarde finale et analyse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sauvegarde finale\n",
        "final_results_file = save_results(all_results, results_dir)\n",
        "print(f\"üíæ Final results saved to: {final_results_file}\")\n",
        "\n",
        "# Analyse rapide des meilleurs r√©sultats\n",
        "successful_results = [r for r in all_results if r['success']]\n",
        "\n",
        "if successful_results:\n",
        "    # Meilleurs r√©sultats par dataset\n",
        "    print(f\"\\nüèÜ BEST RESULTS BY DATASET:\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for dataset_name in datasets.keys():\n",
        "        dataset_results = [r for r in successful_results if r['dataset'] == dataset_name]\n",
        "        if dataset_results:\n",
        "            best_result = min(dataset_results, key=lambda x: x['mean_score'])\n",
        "            print(f\"\\nüìä {dataset_name}:\")\n",
        "            print(f\"   üéØ Best score: {best_result['mean_score']:.6f} ¬± {best_result['std_score']:.6f}\")\n",
        "            print(f\"   üîß Œª_gate_reg: {best_result['model_config']['lambda_gate_reg']:.0e}\")\n",
        "            print(f\"   üîß Œª_orthogonal: {best_result['model_config']['lambda_orthogonal']:.0e}\")\n",
        "            print(f\"   üéõÔ∏è  Avg gate: {np.mean(best_result['final_gate_values']):.3f}\")\n",
        "            print(f\"   üîÄ Avg orth_viol: {np.mean(best_result['orthogonality_violations']):.4f}\")\n",
        "        else:\n",
        "            print(f\"\\n‚ùå {dataset_name}: No successful runs\")\n",
        "    \n",
        "    # Top 5 configurations globales\n",
        "    print(f\"\\nüåü TOP 5 GLOBAL CONFIGURATIONS:\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    top_5 = sorted(successful_results, key=lambda x: x['mean_score'])[:5]\n",
        "    for i, result in enumerate(top_5, 1):\n",
        "        print(f\"\\n{i}. {result['dataset']}:\")\n",
        "        print(f\"   Score: {result['mean_score']:.6f}\")\n",
        "        print(f\"   Œª_gate_reg: {result['model_config']['lambda_gate_reg']:.0e}\")\n",
        "        print(f\"   Œª_orthogonal: {result['model_config']['lambda_orthogonal']:.0e}\")\n",
        "        print(f\"   Gate: {np.mean(result['final_gate_values']):.3f}\")\n",
        "        print(f\"   Orth_viol: {np.mean(result['orthogonality_violations']):.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No successful experiments!\")\n",
        "\n",
        "print(f\"\\nüìÅ All results saved in: {results_dir}\")\n",
        "print(f\"üåÖ Ready for morning analysis!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualisation rapide des r√©sultats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if successful_results:\n",
        "    # Pr√©paration des donn√©es pour visualisation\n",
        "    viz_data = []\n",
        "    for result in successful_results:\n",
        "        viz_data.append({\n",
        "            'dataset': result['dataset'],\n",
        "            'lambda_gate_reg': result['model_config']['lambda_gate_reg'],\n",
        "            'lambda_orthogonal': result['model_config']['lambda_orthogonal'],\n",
        "            'score': result['mean_score'],\n",
        "            'gate_value': np.mean(result['final_gate_values']),\n",
        "            'orth_violation': np.mean(result['orthogonality_violations'])\n",
        "        })\n",
        "    \n",
        "    df_viz = pd.DataFrame(viz_data)\n",
        "    \n",
        "    # Heatmap des scores\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    for i, dataset_name in enumerate(datasets.keys()):\n",
        "        ax = axes[i//2, i%2]\n",
        "        \n",
        "        dataset_df = df_viz[df_viz['dataset'] == dataset_name]\n",
        "        if not dataset_df.empty:\n",
        "            # Pivot pour heatmap\n",
        "            pivot = dataset_df.pivot_table(\n",
        "                values='score', \n",
        "                index='lambda_orthogonal', \n",
        "                columns='lambda_gate_reg', \n",
        "                aggfunc='mean'\n",
        "            )\n",
        "            \n",
        "            sns.heatmap(pivot, annot=True, fmt='.6f', cmap='viridis_r', ax=ax)\n",
        "            ax.set_title(f'{dataset_name}\\nValidation Loss Heatmap')\n",
        "            ax.set_xlabel('Œª_gate_reg')\n",
        "            ax.set_ylabel('Œª_orthogonal')\n",
        "    \n",
        "    # Heatmap des gate values\n",
        "    ax = axes[1, 0]\n",
        "    pivot_gate = df_viz.pivot_table(\n",
        "        values='gate_value', \n",
        "        index='lambda_orthogonal', \n",
        "        columns='lambda_gate_reg', \n",
        "        aggfunc='mean'\n",
        "    )\n",
        "    sns.heatmap(pivot_gate, annot=True, fmt='.3f', cmap='RdYlBu', ax=ax)\n",
        "    ax.set_title('Average Gate Values\\n(KAN Contribution)')\n",
        "    ax.set_xlabel('Œª_gate_reg')\n",
        "    ax.set_ylabel('Œª_orthogonal')\n",
        "    \n",
        "    # Heatmap des violations d'orthogonalit√©\n",
        "    ax = axes[1, 1]\n",
        "    pivot_orth = df_viz.pivot_table(\n",
        "        values='orth_violation', \n",
        "        index='lambda_orthogonal', \n",
        "        columns='lambda_gate_reg', \n",
        "        aggfunc='mean'\n",
        "    )\n",
        "    sns.heatmap(pivot_orth, annot=True, fmt='.4f', cmap='Reds', ax=ax)\n",
        "    ax.set_title('Orthogonality Violations\\n(Lower is better)')\n",
        "    ax.set_xlabel('Œª_gate_reg')\n",
        "    ax.set_ylabel('Œª_orthogonal')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Sauvegarde\n",
        "    viz_file = results_dir / 'hyperparams_heatmaps.png'\n",
        "    plt.savefig(viz_file, dpi=300, bbox_inches='tight')\n",
        "    print(f\"üìä Heatmaps saved to: {viz_file}\")\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    # R√©sum√© statistique\n",
        "    print(f\"\\nüìà STATISTICAL SUMMARY:\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"üìä Total experiments: {len(all_results)}\")\n",
        "    print(f\"‚úÖ Successful: {len(successful_results)} ({len(successful_results)/len(all_results)*100:.1f}%)\")\n",
        "    print(f\"üìâ Best score: {min(r['mean_score'] for r in successful_results):.6f}\")\n",
        "    print(f\"üìà Worst score: {max(r['mean_score'] for r in successful_results):.6f}\")\n",
        "    print(f\"üéõÔ∏è  Gate range: [{min(r['gate_value'] for r in successful_results):.3f}, {max(r['gate_value'] for r in successful_results):.3f}]\")\n",
        "    print(f\"üîÄ Orth violation range: [{min(r['orth_violation'] for r in successful_results):.4f}, {max(r['orth_violation'] for r in successful_results):.4f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
