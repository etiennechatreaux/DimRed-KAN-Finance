{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663b5b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "Total memory: 8.0 GB\n",
      "Memory available: 6.9 GB\n",
      "Device : cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "# from models.ae_kan import KANAutoencoder\n",
    "from src.utils.new_preprocessing import preprocessing_dataset, simple_train_kan, change_hyperparam\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Total memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"Memory available: {torch.cuda.mem_get_info()[0] / 1024**3:.1f} GB\")\n",
    "\n",
    "print(f\"Device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2b93c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"data/processed/sectors\")\n",
    "sectors_list = [d.name for d in data_dir.iterdir() if d.is_dir() and d.name != 'unknown']\n",
    "\n",
    "sector_log_returns = {}\n",
    "for sector in sectors_list:\n",
    "    returns_path = data_dir / sector / \"log_returns.csv\"\n",
    "    df = pd.read_csv(returns_path, index_col=0)\n",
    "    sector_log_returns[sector] = df.iloc[1:]  # Skip first row with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0590b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sector: utilities\n",
      "Train: 2987 échantillons\n",
      "Test: 747 échantillons\n",
      "Dates train: 2010-03-03 à 2022-01-10\n",
      "Dates test: 2022-01-11 à 2024-12-31\n"
     ]
    }
   ],
   "source": [
    "X_df = {}\n",
    "W_df = {}\n",
    "M_df = {}\n",
    "data = {}\n",
    "\n",
    "for sector in sector_log_returns:\n",
    "    # Preprocess data for each sector\n",
    "    X_df[sector], W_df[sector], M_df[sector] = preprocessing_dataset(\n",
    "        log_returns_df=sector_log_returns[sector],\n",
    "        win=60,\n",
    "        min_periods=40,\n",
    "        clip_val=3.0,\n",
    "        min_valid_per_day=5,\n",
    "        use_median=True,\n",
    "        soft_weights=True\n",
    "    )\n",
    "    \n",
    "    # Create tensors for each sector\n",
    "    tensors = {\n",
    "        'X': torch.tensor(X_df[sector].values, dtype=torch.float32),\n",
    "        'W': torch.tensor(W_df[sector].values, dtype=torch.float32),\n",
    "        'M': torch.tensor(M_df[sector].values, dtype=torch.float32)\n",
    "    }\n",
    "\n",
    "    # Split into train/test for each sector\n",
    "    train_size = int(0.8 * len(tensors['X']))\n",
    "    data[sector] = {\n",
    "        'train': {\n",
    "            'X': tensors['X'][:train_size],\n",
    "            'W': tensors['W'][:train_size],\n",
    "            'M': tensors['M'][:train_size]\n",
    "        },\n",
    "        'test': {\n",
    "            'X': tensors['X'][train_size:],\n",
    "            'W': tensors['W'][train_size:],\n",
    "            'M': tensors['M'][train_size:]\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(f\"\\nSector: {sector}\")\n",
    "print(f\"Train: {data[sector]['train']['X'].shape[0]} échantillons\")\n",
    "print(f\"Test: {data[sector]['test']['X'].shape[0]} échantillons\") \n",
    "print(f\"Dates train: {X_df[sector].index[0]} à {X_df[sector].index[train_size-1]}\")\n",
    "print(f\"Dates test: {X_df[sector].index[train_size]} à {X_df[sector].index[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255a5377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7095, -0.2273,  1.4788,  ...,  0.6971, -0.0319,  0.1895],\n",
       "        [ 0.5891, -0.2844, -0.7470,  ..., -0.0982, -0.4259, -0.9280],\n",
       "        [ 0.3553,  0.0000,  0.2215,  ...,  0.7744, -0.5840, -0.4092],\n",
       "        ...,\n",
       "        [-0.0682,  0.0000,  0.2831,  ...,  0.9535, -0.1712, -0.3092],\n",
       "        [-0.2909,  1.1647, -0.8697,  ...,  0.6001,  0.0765,  0.1190],\n",
       "        [-0.4511, -0.1024,  0.0603,  ..., -0.0457,  0.0000,  1.2413]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"utilities\"][\"train\"][\"X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f50ef",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f94c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = {}\n",
    "W_df = {}\n",
    "M_df = {}\n",
    "data = {}\n",
    "\n",
    "for sector in sector_log_returns:\n",
    "    # Preprocess data for each sector\n",
    "    X_df[sector], W_df[sector], M_df[sector] = preprocessing_dataset(\n",
    "        log_returns_df=sector_log_returns[sector],\n",
    "        win=60,\n",
    "        min_periods=40,\n",
    "        clip_val=3.0,\n",
    "        min_valid_per_day=5,\n",
    "        use_median=True,\n",
    "        soft_weights=True\n",
    "    )\n",
    "    \n",
    "    # Create tensors for each sector\n",
    "    tensors = {\n",
    "        'X': torch.tensor(X_df[sector].values, dtype=torch.float32),\n",
    "        'W': torch.tensor(W_df[sector].values, dtype=torch.float32),\n",
    "        'M': torch.tensor(M_df[sector].values, dtype=torch.float32)\n",
    "    }\n",
    "\n",
    "    # Split into train/test for each sector\n",
    "    train_size = int(0.8 * len(tensors['X']))\n",
    "    data[sector] = {\n",
    "        'train': {\n",
    "            'X': tensors['X'][:train_size],\n",
    "            'W': tensors['W'][:train_size],\n",
    "            'M': tensors['M'][:train_size]\n",
    "        },\n",
    "        'test': {\n",
    "            'X': tensors['X'][train_size:],\n",
    "            'W': tensors['W'][train_size:],\n",
    "            'M': tensors['M'][train_size:]\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(f\"\\nSector: {sector}\")\n",
    "print(f\"Train: {data[sector]['train']['X'].shape[0]} échantillons\")\n",
    "print(f\"Test: {data[sector]['test']['X'].shape[0]} échantillons\") \n",
    "print(f\"Dates train: {X_df[sector].index[0]} à {X_df[sector].index[train_size-1]}\")\n",
    "print(f\"Dates test: {X_df[sector].index[train_size]} à {X_df[sector].index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17557300",
   "metadata": {},
   "source": [
    "# KAN AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433baa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.new_preprocessing import hyperparameter_comparison\n",
    "\n",
    "sector = \"financials\"\n",
    "\n",
    "hyperparams = {\n",
    "    'hidden_dims_choices': [32, 16],\n",
    "    'latent_dims': 8,\n",
    "    \n",
    "    # BASIS\n",
    "    'basis_types': 'spline',\n",
    "    'M_values': 16,\n",
    "    'poly_degrees': 3,\n",
    "    'use_silu_choices': True,\n",
    "    'dropout_rates': 0,\n",
    "    \n",
    "    # SKIP LINEAIRE\n",
    "    'use_global_skip': True,\n",
    "    'use_skip_choices': False,\n",
    "    'skip_init_choices': 'identity',\n",
    "    'skip_gain_values': 0.1,\n",
    "    'max_skip_gain': 0.3,\n",
    "    \n",
    "    # REGULARISATION\n",
    "    'lambda_alpha_values': 1e-3,\n",
    "    'lambda_group_values': 1e-4,\n",
    "    'lambda_tv_values': 1e-5,\n",
    "    'lambda_poly_decay_values': 1e-6,\n",
    "    'lambda_skip_l2_values': 1e-3,\n",
    "    'lambda_reg_values': 1e-4,\n",
    "    \n",
    "    # LOSS\n",
    "    'loss_types': 'huber',\n",
    "    'huber_deltas': 1.0,\n",
    "    \n",
    "    # OPTIMISATION\n",
    "    'batch_sizes': 64,\n",
    "    'learning_rates': 0.0002,\n",
    "    'weight_decays': 0.000001\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
