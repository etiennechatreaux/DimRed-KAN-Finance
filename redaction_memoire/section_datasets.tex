\section{Datasets}

Pour valider notre approche de réduction de dimensionnalité non-linéaire basée sur les réseaux de Kolmogorov-Arnold (KANs), nous avons adopté une stratégie progressive en trois étapes. Nous commençons par des expériences préliminaires sur un dataset standard de vision par ordinateur pour valider l'architecture, puis nous appliquons notre méthode à deux cas d'usage financiers distincts : les rendements d'actions en coupe transversale et les courbes de taux d'intérêt.

\subsection{MNIST (Preliminary Experiments)}

Le dataset MNIST constitue notre point de départ expérimental. Bien qu'il s'agisse d'un dataset de vision par ordinateur contenant 70,000 images de chiffres manuscrits (60,000 pour l'entraînement et 10,000 pour le test), son utilisation présente plusieurs avantages méthodologiques pour notre étude. Premièrement, MNIST est largement reconnu comme un benchmark standard, permettant une comparaison directe avec les méthodes existantes de réduction de dimensionnalité. Deuxièmement, avec ses 784 dimensions (images 28×28 pixels), il offre un problème de haute dimensionnalité similaire à ceux rencontrés en finance, tout en restant computationnellement tractable pour l'exploration d'hyperparamètres.

Dans notre contexte, nous utilisons MNIST pour trois objectifs principaux : (1) valider que notre architecture KAN-AE peut effectivement capturer des structures non-linéaires complexes, (2) comparer les performances de reconstruction avec des autoencodeurs classiques et la PCA, et (3) optimiser les hyperparamètres de notre modèle (nombre de fonctions de base, dimension latente, architecture du réseau) avant de passer aux données financières plus complexes. Cette approche nous permet d'identifier rapidement les configurations prometteuses sans les coûts computationnels associés aux données financières de haute fréquence.

\subsection{Cross-sectional Equity Returns}

Notre premier cas d'application financière concerne les rendements d'actions en coupe transversale. Nous utilisons un univers de 500 actions du S\&P 500, couvrant la période de janvier 2018 à décembre 2023, soit approximativement 1,500 jours de trading. Les données proviennent de Bloomberg et incluent les rendements journaliers ajustés pour les dividendes et les splits. Cette configuration génère une matrice de dimensions 1,500 × 500, où chaque ligne représente une date et chaque colonne une action.

Le prétraitement des données suit les pratiques standards de la littérature sur les modèles factoriels. Nous appliquons d'abord un winsorizing à 1\% et 99\% pour limiter l'impact des valeurs extrêmes, particulièrement importantes durant les périodes de volatilité comme la crise COVID-19 de 2020. Ensuite, nous standardisons les rendements en coupe transversale pour chaque date, assurant une moyenne de zéro et un écart-type unitaire. Cette normalisation est cruciale car elle permet au modèle de se concentrer sur les patterns de co-mouvement relatifs plutôt que sur les niveaux absolus de rendement.

Un aspect particulier de notre approche est le traitement des données manquantes. Contrairement aux méthodes traditionnelles qui utilisent l'imputation ou l'exclusion, nous développons une variante pondérée de notre KAN-AE qui peut directement gérer les valeurs manquantes via un système de masques et de poids de fiabilité. Cela nous permet de conserver l'intégralité de l'information disponible, particulièrement importante pour les actions récemment introduites dans l'indice ou temporairement suspendues.

\subsection{Yield Curves}

Le second cas d'application porte sur les courbes de taux d'intérêt, un domaine où les modèles factoriels traditionnels (notamment le modèle de Nelson-Siegel) dominent depuis des décennies. Nous utilisons les taux zero-coupon du Trésor américain pour 11 maturités standards : 3 mois, 6 mois, 1 an, 2 ans, 3 ans, 5 ans, 7 ans, 10 ans, 15 ans, 20 ans et 30 ans. Les données couvrent la période de janvier 2010 à décembre 2023, capturant ainsi différents régimes de politique monétaire incluant la période de taux zéro post-2008, la normalisation progressive, et le cycle de resserrement récent.

Ce dataset présente des caractéristiques uniques qui le rendent particulièrement intéressant pour notre étude. Premièrement, les courbes de taux exhibent une structure de corrélation très forte et hautement non-linéaire, avec des mouvements typiques bien documentés (déplacements parallèles, changements de pente, modifications de courbure). Deuxièmement, contrairement aux rendements d'actions qui sont approximativement i.i.d. après standardisation, les taux d'intérêt présentent une forte persistance temporelle et des dynamiques de mean-reversion complexes.

Pour ce dataset, nous explorons deux représentations : (1) les niveaux absolus des taux, qui permettent de capturer la forme complète de la courbe, et (2) les variations journalières, qui se concentrent sur la dynamique de court terme. Cette double approche nous permet d'évaluer la capacité de notre modèle à capturer à la fois les caractéristiques statiques (forme de la courbe) et dynamiques (co-mouvements des taux) du marché obligataire.

Un défi particulier avec les données de courbe de taux est la gestion des contraintes d'arbitrage. Les taux de différentes maturités ne peuvent pas évoluer de manière complètement indépendante sans créer des opportunités d'arbitrage. Notre approche KAN, avec sa capacité à apprendre des transformations non-linéaires complexes, devrait théoriquement pouvoir capturer ces contraintes implicitement, contrairement à la PCA qui impose une structure linéaire potentiellement incompatible avec ces contraintes économiques.

Pour chaque dataset, nous appliquons une division temporelle 70/15/15 pour les ensembles d'entraînement, validation et test. Cette approche, plutôt qu'une division aléatoire, respecte la structure temporelle des données financières et évite le look-ahead bias. De plus, nous conservons systématiquement les 100 dernières observations comme ensemble de test "out-of-sample" pour évaluer la capacité de généralisation de notre modèle dans des conditions de marché potentiellement différentes de celles observées durant l'entraînement.